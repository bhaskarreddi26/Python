{"cells":[{"cell_type":"code","source":["rdd=sc.textFile(\"/FileStore/tables/1800/1800.csv\") \\\n    .map(lambda line: line.split(',')) \\\n    .filter(lambda line: len(line)>1) \\\n    .map(lambda line: (line[0],line[1],line[2],line[3])) \nrdd.collect()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["df = spark.createDataFrame([(1, 4), (2, 5), (3, 6)], [\"A\", \"B\"])\nprint df.collect()\nprint df.show()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#people = spark.read.json('/FileStore/tables/people.json')\ndf = spark.read.json('/FileStore/tables/employees.json')\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["df.createGlobalTempView(\"people\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["df2 = spark.sql(\"select * from global_temp.people\")"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["df2.show()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["%fs ls /FileStore/tables/"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["df.explain()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["stringJSONRDD = sc.parallelize((\"\"\" \n  { \"id\": \"123\",\n    \"name\": \"Katie\",\n    \"age\": 19,\n    \"eyeColor\": \"brown\"\n  }\"\"\",\n   \"\"\"{\n    \"id\": \"234\",\n    \"name\": \"Michael\",\n    \"age\": 22,\n    \"eyeColor\": \"green\"\n  }\"\"\", \n  \"\"\"{\n    \"id\": \"345\",\n    \"name\": \"Simone\",\n    \"age\": 23,\n    \"eyeColor\": \"blue\"\n  }\"\"\")\n)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["swimmersJSON = spark.read.json(stringJSONRDD)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["swimmersJSON.createOrReplaceTempView(\"swimmersJSON\")\nprint swimmersJSON.show()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["spark.sql(\"select * from swimmersJSON\").show()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["swimmersJSON.printSchema()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# import pyspark class Row from module sql\nfrom pyspark.sql import *\n\n# Create Example Data - Departments and Employees\n\n# Create the Departments\ndepartment1 = Row(id='123456', name='Computer Science')\ndepartment2 = Row(id='789012', name='Mechanical Engineering')\ndepartment3 = Row(id='345678', name='Theater and Drama')\ndepartment4 = Row(id='901234', name='Indoor Recreation')\n\n# Create the Employees\nEmployee = Row(\"firstName\", \"lastName\", \"email\", \"salary\")\nemployee1 = Employee('michael', 'armbrust', 'no-reply@berkeley.edu', 100000)\nemployee11 = Employee('michael', 'armbrust', 'no-reply@berkeley.edu', 200000)\nemployee2 = Employee('xiangrui', 'meng', 'no-reply@stanford.edu', 120000)\nemployee3 = Employee('matei', None, 'no-reply@waterloo.edu', 140000)\nemployee31 = Employee('matei', None, 'no-reply@waterloo.edu', 180000)\nemployee4 = Employee(None, 'wendell', 'no-reply@berkeley.edu', 160000)\n\n# Create the DepartmentWithEmployees instances from Departments and Employees\ndepartmentWithEmployees1 = Row(department=department1, employees=[employee1, employee2])\ndepartmentWithEmployees2 = Row(department=department2, employees=[employee3, employee4, employee11])\ndepartmentWithEmployees3 = Row(department=department3, employees=[employee1, employee4, employee31])\ndepartmentWithEmployees4 = Row(department=department4, employees=[employee2, employee3])"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":16}],"metadata":{"name":"Day2","notebookId":2343800872585588},"nbformat":4,"nbformat_minor":0}
