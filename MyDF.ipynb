{"cells":[{"cell_type":"code","source":["wb = spark.read.json('/FileStore/tables/world_bank.json')"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["wb.show(2)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["wb.printSchema()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["wb.createOrReplaceTempView('world_bank')"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["df1 = spark.sql(\"select countryshortname from world_bank\")\ndf1.show(2)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["wb.createGlobalTempView(\"bhaskar\")"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["df3 = spark.sql(\"SELECT  distinct approvalfy FROM global_temp.bhaskar WHERE countryshortname = 'Tunisia' \")"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["df3.show()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["df4 = spark.sql(\"SELECT  distinct countryshortname FROM global_temp.bhaskar WHERE approvalfy = '2013' \")"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["df4.count()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["df3 = spark.sql(\"SELECT  distinct approvalfy FROM global_temp.bhaskar WHERE countryshortname = 'Tunisia' \")\ndf4 = spark.sql(\"SELECT  distinct countryshortname FROM global_temp.bhaskar WHERE approvalfy = '2013' \")\nprint df3.show()\nprint df.count()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["zpis = spark.read.json('/FileStore/tables/zips.json')\nstocks = spark.read.json('/FileStore/tables/stocks.json')\nenron = spark.read.json('/FileStore/tables/enron.json')\ncompanies = spark.read.json('/FileStore/tables/companies.json')"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["enron.printSchema()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["from pyspark.sql.functions import *\nfrom pyspark.sql.types import *\n\ndef getter(column):\n\n    for i,col in enumerate(column):\n        if i==1:\n           col_new=col\n        else:\n           col_new=col_new+','+col\n    return col_new\n\ngetterUDF = udf(getter, StringType())\n\ndf.select(getterUDF(enron.cc))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#zpis[['loc']].show()\nfrom pyspark.sql.functions import to_json, from_json, col, struct, lit\nfrom pyspark.sql.types import StructType, StructField\nfrom pyspark.ml.linalg import VectorUDT\n\njson_vec = to_json(struct(struct(\n    lit(1).alias(\"type\"),  # type 1 is dense, type 0 is sparse\n    col(\"zpis.loc\").alias(\"values\")\n).alias(\"v\")))\n\nschema = StructType([StructField(\"v\", VectorUDT())])\n\nwith_parsed_vector = df.withColumn(\n    \"parsed_vector\", from_json(json_vec, schema).getItem(\"v\")\n)\n\nwith_parsed_vector.show()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["zpis.write.parquet(\"zpis1.parquet\")"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["zpis1 = spark.read.parquet('zpis1.parquet')"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["print zpis1.show(2)\nprint zpis.show(2)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["#zpis1.createGlobalTempView('zpis1')\n\nspark.catalog.refreshTable(\"global_temp.zpis1\")"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["zpis.printSchema()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["import pyspark.ml.feature as ft"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["transformed_id = ft.StringIndexer(inputCol='_id', outputCol='id_en')\ntransformed_city = ft.StringIndexer(inputCol='city', outputCol='city_en')\ntransformed_state = ft.StringIndexer(inputCol='state', outputCol='state_en')"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["transfor"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["featurescreator = ft.VectorAssembler(inputCols=['id_en',\n                                     'city_en',\n                                     \"features[{2}]\". format(i) for i in range(n)\n                                     'state_en' ], outputCol='features')"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["import pyspark.ml.classification as cl"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["createLogistic = cl.LogisticRegression(maxIter=10, regParam=0.01, labelCol='pop')"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["from pyspark.ml import Pipeline"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["pipeline = Pipeline(stages=[transformed_id,\n                            transformed_city,\n                            transformed_state,\n                           featurescreator,\n                           createLogistic])"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["zpis_train, zpis_test = zpis.randomSplit([0.7, 0.3], seed=100)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["model = pipeline.fit(zpis_train)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["test_out = model.transform(zpis_test)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["test_out"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["#To find accuracy of the algo under processing\nimport pyspark.ml.evaluation as ev"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["\n#BinaryClassification\nevaluator = ev.BinaryClassificationEvaluator(rawPredictionCol='probability', \n                                             labelCol='pop')"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["evaluator.evaluate(test_out)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["zpis = spark.read.json('/FileStore/tables/zips.json')"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["from pyspark.sql.functions import to_json, from_json, col, struct, lit\nfrom pyspark.sql.types import StructType, StructField\nfrom pyspark.ml.linalg import VectorUDT\n\njson_vec = to_json(struct(struct(lit(1).\n                                  col('loc')\n).alias(\"v\")))\n\nschema = StructType([StructField(\"v\", VectorUDT())])\n\nwith_parsed_vector = df.withColumn(\n    \"parsed_vector\", from_json(json_vec, schema).getItem(\"v\")\n)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["with_vec = df.withColumn(\"loc\", as_vector(\"loc\"))\nwith_vec.show()"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["zpis.show(2)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["companies = spark.read.json('/FileStore/tables/companies.json')"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["companies.show(2)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":42}],"metadata":{"name":"MyDF","notebookId":620808971867608},"nbformat":4,"nbformat_minor":0}
