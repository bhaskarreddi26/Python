{"cells":[{"cell_type":"code","source":["import pyspark.sql.types as typ\n\nlabels = [\n    ('INFANT_ALIVE_AT_REPORT', typ.StringType()),\n    ('BIRTH_YEAR', typ.IntegerType()),\n    ('BIRTH_MONTH', typ.IntegerType()),\n    ('BIRTH_PLACE', typ.StringType()),\n    ('MOTHER_AGE_YEARS', typ.IntegerType()),\n    ('MOTHER_RACE_6CODE', typ.StringType()),\n    ('MOTHER_EDUCATION', typ.StringType()),\n    ('FATHER_COMBINED_AGE', typ.IntegerType()),\n    ('FATHER_EDUCATION', typ.StringType()),\n    ('MONTH_PRECARE_RECODE', typ.StringType()),\n    ('CIG_BEFORE', typ.IntegerType()),\n    ('CIG_1_TRI', typ.IntegerType()),\n    ('CIG_2_TRI', typ.IntegerType()),\n    ('CIG_3_TRI', typ.IntegerType()),\n    ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n    ('MOTHER_BMI_RECODE', typ.IntegerType()),\n    ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n    ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n    ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n    ('DIABETES_PRE', typ.StringType()),\n    ('DIABETES_GEST', typ.StringType()),\n    ('HYP_TENS_PRE', typ.StringType()),\n    ('HYP_TENS_GEST', typ.StringType()),\n    ('PREV_BIRTH_PRETERM', typ.StringType()),\n    ('NO_RISK', typ.StringType()),\n    ('NO_INFECTIONS_REPORTED', typ.StringType()),\n    ('LABOR_IND', typ.StringType()),\n    ('LABOR_AUGM', typ.StringType()),\n    ('STEROIDS', typ.StringType()),\n    ('ANTIBIOTICS', typ.StringType()),\n    ('ANESTHESIA', typ.StringType()),\n    ('DELIV_METHOD_RECODE_COMB', typ.StringType()),\n    ('ATTENDANT_BIRTH', typ.StringType()),\n    ('APGAR_5', typ.IntegerType()),\n    ('APGAR_5_RECODE', typ.StringType()),\n    ('APGAR_10', typ.IntegerType()),\n    ('APGAR_10_RECODE', typ.StringType()),\n    ('INFANT_SEX', typ.StringType()),\n    ('OBSTETRIC_GESTATION_WEEKS', typ.IntegerType()),\n    ('INFANT_WEIGHT_GRAMS', typ.IntegerType()),\n    ('INFANT_ASSIST_VENTI', typ.StringType()),\n    ('INFANT_ASSIST_VENTI_6HRS', typ.StringType()),\n    ('INFANT_NICU_ADMISSION', typ.StringType()),\n    ('INFANT_SURFACANT', typ.StringType()),\n    ('INFANT_ANTIBIOTICS', typ.StringType()),\n    ('INFANT_SEIZURES', typ.StringType()),\n    ('INFANT_NO_ABNORMALITIES', typ.StringType()),\n    ('INFANT_ANCEPHALY', typ.StringType()),\n    ('INFANT_MENINGOMYELOCELE', typ.StringType()),\n    ('INFANT_LIMB_REDUCTION', typ.StringType()),\n    ('INFANT_DOWN_SYNDROME', typ.StringType()),\n    ('INFANT_SUSPECTED_CHROMOSOMAL_DISORDER', typ.StringType()),\n    ('INFANT_NO_CONGENITAL_ANOMALIES_CHECKED', typ.StringType()),\n    ('INFANT_BREASTFED', typ.StringType())\n]\n\nschema = typ.StructType([\n        typ.StructField(e[0], e[1], False) for e in labels\n    ])"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["births = spark.read.csv('/FileStore/tables/births_train_csv-dc6be.gz', \n                        header=True, \n                        schema=schema)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["births.show()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["births.printSchema()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#Specify our recode dictionary.\nrecode_dictionary = {\n    'YNU': {\n        'Y': 1,\n        'N': 0,\n        'U': 0\n    }\n}"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#Our goal is to predict whether the 'INFANT_ALIVE_AT_REPORT' is either 1 or 0. Thus, we will drop all of the features that relate to the infant.\nselected_features = [\n    'INFANT_ALIVE_AT_REPORT', \n    'BIRTH_PLACE', \n    'MOTHER_AGE_YEARS', \n    'FATHER_COMBINED_AGE', \n    'CIG_BEFORE', \n    'CIG_1_TRI', \n    'CIG_2_TRI', \n    'CIG_3_TRI', \n    'MOTHER_HEIGHT_IN', \n    'MOTHER_PRE_WEIGHT', \n    'MOTHER_DELIVERY_WEIGHT', \n    'MOTHER_WEIGHT_GAIN', \n    'DIABETES_PRE', \n    'DIABETES_GEST', \n    'HYP_TENS_PRE', \n    'HYP_TENS_GEST', \n    'PREV_BIRTH_PRETERM'\n]\n\nbirths_trimmed = births.select(selected_features)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["births_trimmed.printSchema()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["births_trimmed.show(5)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#Specify the recoding methods.\nimport pyspark.sql.functions as func\n\ndef recode(col, key):        \n    return recode_dictionary[key][col] \n\nrec_integer = func.udf(recode, typ.IntegerType())\n\n#Define some funtion\ndef correct_cig(feat):\n    return func \\\n        .when(func.col(feat) != 99, func.col(feat))\\\n        .otherwise(0)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#Correct the features related to the number of smoked cigarettes.\nbirths_transformed = births_trimmed \\\n    .withColumn('CIG_BEFORE', correct_cig('CIG_BEFORE'))\\\n    .withColumn('CIG_1_TRI', correct_cig('CIG_1_TRI'))\\\n    .withColumn('CIG_2_TRI', correct_cig('CIG_2_TRI'))\\\n    .withColumn('CIG_3_TRI', correct_cig('CIG_3_TRI'))"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["births_transformed.printSchema()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#Figure out which Yes/No/Unknown features are.\ncols = [(col.name, col.dataType) for col in births_trimmed.schema]\n\nYNU_cols = []\n\nfor i, s in enumerate(cols):\n    if s[1] == typ.StringType():\n        dis = births.select(s[0]) \\\n            .distinct() \\\n            .rdd \\\n            .map(lambda row: row[0]) \\\n            .collect()\n\n        if 'Y' in dis:\n            YNU_cols.append(s[0])"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#Checking the either it's updating the vlaues or not DataFrames can transform the features in bulk while selecting features.\nbirths.select([\n        'INFANT_NICU_ADMISSION', \n        rec_integer(\n            'INFANT_NICU_ADMISSION', func.lit('YNU')\n        ) \\\n        .alias('INFANT_NICU_ADMISSION_RECODE')]\n     ).take(5)\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["#Transform all the YNU_cols in one using a list of transformations.\nexprs_YNU = [\n    rec_integer(x, func.lit('YNU')).alias(x) \n    if x in YNU_cols \n    else x \n    for x in births_transformed.columns\n]\n\nbirths_transformed = births_transformed.select(exprs_YNU)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#[-7:] means it'll shows the impacted rows only event hough your given more number\nbirths_transformed.select(YNU_cols[-7:]).show(5)\n#births_transformed.show(2)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#Get to know your data\n#Descriptive statistics\n#We will use the colStats(...) method.\n\nimport pyspark.mllib.stat as st\nimport numpy as np\n\nnumeric_cols = ['MOTHER_AGE_YEARS','FATHER_COMBINED_AGE',\n                'CIG_BEFORE','CIG_1_TRI','CIG_2_TRI','CIG_3_TRI',\n                'MOTHER_HEIGHT_IN','MOTHER_PRE_WEIGHT',\n                'MOTHER_DELIVERY_WEIGHT','MOTHER_WEIGHT_GAIN'\n               ]\n\nnumeric_rdd = births_transformed\\\n                       .select(numeric_cols)\\\n                       .rdd \\\n                       .map(lambda row: [e for e in row])\n\nmllib_stats = st.Statistics.colStats(numeric_rdd)\n\nfor col, m, v in zip(numeric_cols, \n                     mllib_stats.mean(), \n                     mllib_stats.variance()):\n    print('{0}: \\t{1:.2f} \\t {2:.2f}'.format(col, m, np.sqrt(v)))"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["#For the categorical variables we will calculate the frequencies of their values.\ncategorical_cols = [e for e in births_transformed.columns \n                    if e not in numeric_cols]\n\ncategorical_rdd = births_transformed\\\n                       .select(categorical_cols)\\\n                       .rdd \\\n                       .map(lambda row: [e for e in row])\n            \nfor i, col in enumerate(categorical_cols):\n    agg = categorical_rdd \\\n        .groupBy(lambda row: row[i]) \\\n        .map(lambda row: (row[0], len(row[1])))\n        \n    print(col, sorted(agg.collect(), \n                      key=lambda el: el[1], \n                      reverse=True))"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":18}],"metadata":{"name":"MLib","notebookId":2529172308591393},"nbformat":4,"nbformat_minor":0}
