{"cells":[{"cell_type":"code","source":["%fs ls /FileStore/tables/"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["HR_data = spark.read.csv('dbfs:/FileStore/tables/HR_comma_sep.csv',inferSchema=True,header=True)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["HR_data.head()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["HR_data.printSchema()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["HR_data[['dept']].distinct().collect()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#renamed the column to new name\nHR_data = HR_data.withColumnRenamed('sales','dept')"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["HR_data[['dept']].show(2) #if we are give one column name we shd need to give double [[]]. so that it'll be a df. otherwise it'll be column operation"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["HR_data.describe().show()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["###Featurization converting the stirng data to numbers\n#StringIndexer is converting the string to numbeArs\nimport pyspark.ml.feature as ft\ntransformer_dept=ft.StringIndexer(inputCol='dept',outputCol='dept_en')\ntransformer_salary=ft.StringIndexer(inputCol='salary',outputCol='salary_en')\n"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#Convert into numbers into verctors==output column name should be features\nFeaturecreate=ft.VectorAssembler(inputCols=[ 'satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'time_spend_company', 'Work_accident',  'promotion_last_5years','dept_en','salary_en'],outputCol='features')"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["HR_data.columns"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["import pyspark.ml.classification as cl"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#Creating estimator\nlogistic = cl.LogisticRegression(maxIter=10,regParam=0.01,labelCol='left')"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["from pyspark.ml import Pipeline"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#Create pipeline connecting transformer and estimator\npipeline=Pipeline(stages=[transformer_dept,transformer_salary,Featurecreate,logistic])"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#Split data for test and train\n#seed control random data generated\nhr_data_train,hr_data_test = HR_data.randomSplit([0.7,0.3],seed=100)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["model=pipeline.fit(hr_data_train)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["test_out=model.transform(hr_data_test)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["test_out"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["test_out[['probability']].take(2)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["import pyspark.ml.evaluation as ev"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["evaluator=ev.BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='left')"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["evaluator.evaluate(test_out)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#Convert the fields type into double\nfrom pyspark.sql.functions import *\n\nhr_data = HR_data.withColumn('left', col('left').cast('double'))"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["hr_data.printSchema()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["\n## Create random forest estimator\nfrom pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(labelCol=\"left\", featuresCol=\"features\", \n                            numTrees=10, maxDepth=5.0)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["pipeline=Pipeline(stages=[transformer_dept,transformer_salary,Featurecreate,rf])"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["#Split data for test & train\n#seed controls the random data generated\nhr_data_train, hr_data_test = hr_data.randomSplit([0.7,0.3],seed=100)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["model = pipeline.fit(hr_data_train)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["\ntest_out = model.transform(hr_data_test)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["test_out.show()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["#BinaryClassification\nevaluator = ev.BinaryClassificationEvaluator(rawPredictionCol='probability', \n                                             labelCol='left')"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["evaluator.evaluate(test_out)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["from pyspark.ml.classification import GBTClassifier"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["gbt = GBTClassifier(labelCol='left', featuresCol='features' , maxIter=10)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["pipeline=Pipeline(stages=[transformer_dept,transformer_salary,Featurecreate,gbt])"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["#Split data for test & train\n#seed controls the random data generated\nhr_data_train, hr_data_test = hr_data.randomSplit([0.7,0.3],seed=100)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["model = pipeline.fit(hr_data_train)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["test_out = model.transform(hr_data_test)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["test_out.show()"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["#BinaryClassification\nevaluator = ev.BinaryClassificationEvaluator(rawPredictionCol='probability', \n                                             labelCol='left')"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["evaluator.evaluate(test_out)"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":43}],"metadata":{"name":"Day4","notebookId":2855536943481161},"nbformat":4,"nbformat_minor":0}
